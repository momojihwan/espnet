# general
batch_type: numel
batch_bins: 1200000
accum_grad: 64
max_epoch: 100 # 100 produces better results.
patience: none
init: none
num_att_plot: 0
# student_checkpoint: /home/user/Workspace/espnet/egs2/librispeech_100/asr1/exp/asr_train_asr_conformer-rnnt-nonstreaming-kd_raw_en_bpe2048_sp/checkpoint.pth
teacher_path: /home/user/Workspace/espnet/egs2/librispeech_100/asr1/exp/asr_train_asr_conformer-rnnt-otg-large_raw_en_bpe2048_sp_0.5/valid.loss.ave_10best.pth
kd_weight: 0.3
temp_tau: 1.0

model_conf:
    transducer_weight: 1.0
    auxiliary_ctc_weight: 0.0
    fastemit_lambda: 0.0
    report_cer: True
    report_wer: True

teacher_encoder_conf:
    main_conf:
      pos_wise_act_type: swish
      conv_mod_act_type: swish
      pos_enc_dropout_rate: 0.2
      dynamic_chunk_training: False
      short_chunk_size: 25
      num_left_chunks: 4
    input_conf:
      vgg_like: True
    body_conf:
    - block_type: conformer
      linear_size: 2048
      hidden_size: 512
      heads: 8
      dropout_rate: 0.1
      pos_wise_dropout_rate: 0.1
      att_dropout_rate: 0.1
      conv_mod_kernel_size: 31
      num_blocks: 17

encoder_conf:
    main_conf:
      pos_wise_act_type: swish
      conv_mod_act_type: swish
      pos_enc_dropout_rate: 0.2
      dynamic_chunk_training: False
      short_chunk_threshold: 0.75
      short_chunk_size: 25
      num_left_chunks: 4
    input_conf:
      vgg_like: True
    body_conf:
    - block_type: conformer
      linear_size: 2048
      hidden_size: 512
      heads: 8
      dropout_rate: 0.1
      pos_wise_dropout_rate: 0.1
      att_dropout_rate: 0.1
      conv_mod_kernel_size: 31
      num_blocks: 12

decoder: rnn
decoder_conf:
    rnn_type: lstm
    num_layers: 1
    embed_size: 512
    hidden_size: 512
    dropout_rate: 0.1
    embed_dropout_rate: 0.2

joint_network_conf:
    joint_space_size: 512


# optimizer
optim: adam
optim_conf:
    lr: 0.001
    weight_decay: 0.000001
scheduler: warmuplr
scheduler_conf:
    warmup_steps: 15000


# criterion
val_scheduler_criterion:
    - valid
    - loss
best_model_criterion:
-   - valid
    - loss
    - min
keep_nbest_models: 10 # 20 produces slightly better results.

# specaug conf
specaug: specaug
specaug_conf:
    apply_time_warp: true
    time_warp_window: 5
    time_warp_mode: bicubic
    apply_freq_mask: true
    freq_mask_width_range:
    - 0
    - 27
    num_freq_mask: 2
    apply_time_mask: true
    time_mask_width_ratio_range:
    - 0.
    - 0.05
    num_time_mask: 10
    # freq_mask_width_range:
    # - 0
    # - 27
    # num_freq_mask: 2
    # apply_time_mask: true
    # time_mask_width_ratio_range:
    # - 0.
    # - 40
    # num_time_mask: 2
